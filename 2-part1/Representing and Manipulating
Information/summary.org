Computers encode information as bits, generally organized as sequences of bytes.
Different encodings are used for representing integers, real numbers, and charac-
ter strings. Different models of computers use different conventions for encoding
numbers and for ordering the bytes within multi-byte data.
The C language is designed to accommodate a wide range of different imple-
mentations in terms of word sizes and numeric encodings. Most current machines
have 32-bit word sizes, although high-end machines increasingly have 64-bit words.
Most machines use two’s-complement encoding of integers and IEEE encod-
ing of ﬂoating point. Understanding these encodings at the bit level, as well as
understanding the mathematical characteristics of the arithmetic operations, is im-
portant for writing programs that operate correctly over the full range of numeric
values.
When casting between signed and unsigned integers of the same size, most
C implementations follow the convention that the underlying bit pattern does
not change. On a two’s-complement machine, this behavior is characterized by
functions T2U w and U2T w , for a w-bit value. The implicit casting of C gives results
that many programmers do not anticipate, often leading to program bugs.
Due to the ﬁnite lengths of the encodings, computer arithmetic has properties
quite different from conventional integer and real arithmetic. The ﬁnite length can
cause numbers to overﬂow, when they exceed the range of the representation.
Floating-point values can also underﬂow, when they are so close to 0.0 that they
are changed to zero.
The ﬁnite integer arithmetic implemented by C, as well as most other pro-
gramming languages, has some peculiar properties compared to true integer arith-
metic. For example, the expression x*x can evaluate to a negative number due
to overﬂow. Nonetheless, both unsigned and two’s-complement arithmetic satisfy
many of the other properties of integer arithmetic, including associativity, com-
mutativity, and distributivity. This allows compilers to do many optimizations. For
example, in replacing the expression 7*x by (x<<3)-x, we make use of the as-
sociative, commutative, and distributive properties, along with the relationship
between shifting and multiplying by powers of 2.
We have seen several clever ways to exploit combinations of bit-level opera-
tions and arithmetic operations. For example, we saw that with two’s-complement
arithmetic ~x+1 is equivalent to -x. As another example, suppose we want a bit
pattern of the form [0, . . . , 0, 1, . . . , 1], consisting of w − k zeros followed by k
ones. Such bit patterns are useful for masking operations. This pattern can be gen-
erated by the C expression (1<<k)-1, exploiting the property that the desired
bit pattern has numeric value 2k − 1. For example, the expression (1<<8)-1 will
generate the bit pattern 0xFF.
Floating-point representations approximate real numbers by encoding num-
bers of the form x × 2y . The most common ﬂoating-point representation is deﬁned
by IEEE Standard 754. It provides for several different precisions, with the most
common being single (32 bits) and double (64 bits). IEEE ﬂoating point also has
representations for special values representing plus and minus inﬁnity, as well as
not-a-number.Floating-point arithmetic must be used very carefully, because it has only
limited range and precision, and because it does not obey common mathematical
properties such as associativity.
